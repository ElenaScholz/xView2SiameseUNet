{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "from typing import Tuple, Dict, List\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader  # Falls du mit einem DataLoader arbeitest\n",
    "\n",
    "from utils.dataset import xView2Dataset, collate_fn_test, image_transform, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = \"di97ren\"\n",
    "# keep the following unchanged\n",
    "ROOT = Path(\"/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022\")\n",
    "USER_HOME_PATH = Path(f\"/dss/dsshome1/08/{USER}\")\n",
    "DATA_PATH = ROOT / \"data\"\n",
    "\n",
    "\n",
    "# Configure the path to the xview2 dataset for your environment\n",
    "DATASET_ROOT = DATA_PATH / \"xview2-subset\"\n",
    "\n",
    "\n",
    "\n",
    "TEST_ROOT = DATASET_ROOT / \"test\"\n",
    "TEST_IMG = TEST_ROOT / \"png_images\"\n",
    "\n",
    "\n",
    "\n",
    "# Pathes to store the experiment information in:\n",
    "EXPERIMENT_GROUP = \"xView2_Subset\"\n",
    "EXPERIMENT_ID = \"003\"\n",
    "\n",
    "EXPERIMENT_DIR = USER_HOME_PATH / EXPERIMENT_GROUP / \"tensorboard_logs\" / EXPERIMENT_ID\n",
    "EXPERIMENT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINTS_DIR = USER_HOME_PATH / EXPERIMENT_GROUP / \"checkpoints\"\n",
    "CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = xView2Dataset(png_path= TEST_IMG,\n",
    "                 image_transform = image_transform(),\n",
    "                 inference = True)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,  # Kann größer sein als beim Training\n",
    "    collate_fn=collate_fn_test,\n",
    "    shuffle=False,  # Bei Inference nicht shuffeln\n",
    "    num_workers=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw state_dict from /dss/dsshome1/08/di97ren/xView2_Subset/checkpoints/003_best_siamese_unet_state.pth\n",
      "Checkpoint erfolgreich in DataParallel-Modell geladen.\n"
     ]
    }
   ],
   "source": [
    "from utils.helperfunctions import find_best_checkpoint, load_checkpoint\n",
    "import torch\n",
    "from model.siameseNetwork import SiameseUnet\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Modell initialisieren\n",
    "model = SiameseUnet(num_pre_classes=2, num_post_classes=6)\n",
    "model.to(device)\n",
    "\n",
    "best_checkpoint_path = find_best_checkpoint(CHECKPOINTS_DIR, EXPERIMENT_ID)\n",
    "\n",
    "# Besten Checkpoint laden\n",
    "model = load_checkpoint(model, best_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([50, 8, 1024, 1024])\n",
      "Pre-outputs stats: min=-8.2386, max=150.5160, mean=4.7182\n",
      "Post-outputs stats: min=-181.8403, max=124.4734, mean=-1.9284\n",
      "Bild 0:\n",
      "  Pre-Klasse 0: min=-0.7193, max=35.4962, mean=7.2498\n",
      "  Pre-Klasse 1: min=-8.2386, max=13.9006, mean=0.8933\n",
      "  Post-Klasse 0: min=-3.5084, max=32.9576, mean=8.3953\n",
      "  Post-Klasse 1: min=-67.8368, max=0.5039, mean=-13.5436\n",
      "  Post-Klasse 2: min=-35.5794, max=2.2669, mean=-5.8434\n",
      "  Post-Klasse 3: min=-35.2704, max=0.2501, mean=-8.1684\n",
      "  Post-Klasse 4: min=-16.9713, max=8.7846, mean=-1.4143\n",
      "  Post-Klasse 5: min=-0.0734, max=31.7061, mean=6.0811\n",
      "Sample at position (100,100):\n",
      "  Pre-logits: tensor([15.9075,  6.2959], device='cuda:0')\n",
      "  Post-logits: tensor([ 12.2762, -19.4789,  -6.7663, -10.3962,  -7.4509,   9.0879],\n",
      "       device='cuda:0')\n",
      "  Pre-probs: tensor([9.9993e-01, 6.6944e-05], device='cuda:0')\n",
      "  Post-probs: tensor([9.6039e-01, 1.5537e-14, 5.1572e-09, 1.3676e-10, 2.6007e-09, 3.9610e-02],\n",
      "       device='cuda:0')\n",
      "Pre-disaster class distribution: {np.int64(0): np.int64(45701480), np.int64(1): np.int64(6727320)}\n",
      "Post-disaster class distribution: {np.int64(0): np.int64(42391284), np.int64(1): np.int64(4559757), np.int64(2): np.int64(501866), np.int64(3): np.int64(280290), np.int64(4): np.int64(310082), np.int64(5): np.int64(4385521)}\n",
      "5 Visualisierungen wurden im Verzeichnis 'predictions_visualizations' gespeichert.\n",
      "Klassenverteilungen wurden in 'predictions_visualizations/class_distribution.png' gespeichert.\n",
      "5 Visualisierungen wurden im Verzeichnis 'predictions_visualizations' gespeichert.\n",
      "Klassenverteilungen wurden in 'predictions_visualizations/class_distribution.png' gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# Inferenz durchführen\n",
    "from utils.inference_step import inference\n",
    "from utils.viz import visualize_predictions\n",
    "results = inference(model, test_dataloader)\n",
    "visualize_predictions(results, num_samples = 5, random_seed = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
