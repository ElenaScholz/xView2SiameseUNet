{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "This notebook is intended to depict the results of inference for the xView2 Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/08/di97ren/04-geo-oma24/xView2SiameseUNet\n"
     ]
    }
   ],
   "source": [
    "from utils.inference_step import inference\n",
    "from utils.helperfunctions import load_checkpoint, find_best_checkpoint, get_data_folder\n",
    "from utils.dataset import xView2Dataset, collate_fn_test, image_transform\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import yaml\n",
    "from model.siameseNetwork import SiameseUnet\n",
    "from model.uNet import UNet_ResNet50\n",
    "from model.loss import FocalLoss, combined_loss_function\n",
    "import torch\n",
    "base_dir = Path(os.getcwd()).parent  # Gehe einen Ordner zurück vom aktuellen Arbeitsverzeichnis\n",
    "config_path = base_dir / \"notebooks\" / \"config1.yaml\"\n",
    "print(base_dir)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all pathes and create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT, TEST_ROOT, VAL_IMG, TEST_LABEL, TEST_TARGET, TEST_PNG_IMAGES = get_data_folder(\"test\", main_dataset = False)\n",
    "\n",
    "test_dataset = xView2Dataset(png_path=TEST_PNG_IMAGES,\n",
    "image_transform = image_transform(), inference = True)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size = 32,\n",
    "    collate_fn = collate_fn_test,\n",
    "    shuffle = False,\n",
    "    num_workers = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/08/di97ren/xView2_all_data/tensorboard_logs/001\n",
      "Logfiles werden gespeichert in: /dss/dsshome1/08/di97ren/xView2_all_data/logfiles/001\n"
     ]
    }
   ],
   "source": [
    "USER = config[\"data\"][\"user\"]\n",
    "#USER_PATH = Path(f\"/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022/users/{USER}\")\n",
    "USER_HOME_PATH = Path(f\"/dss/dsshome1/08/{USER}\")\n",
    "\n",
    "# Pathes to store experiment informations in:\n",
    "EXPERIMENT_GROUP = config[\"data\"][\"experiment_group\"]\n",
    "EXPERIMENT_ID = config[\"data\"][\"experiment_id\"]\n",
    "EXPERIMENT_DIR = USER_HOME_PATH / EXPERIMENT_GROUP / \"tensorboard_logs\" / EXPERIMENT_ID\n",
    "EXPERIMENT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(EXPERIMENT_DIR)\n",
    "\n",
    "# Auch Checkpoints-Verzeichnis erstellen\n",
    "CHECKPOINTS_DIR = USER_HOME_PATH / EXPERIMENT_GROUP / \"checkpoints\"\n",
    "CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Logfiles-Verzeichnis erstellen\n",
    "LOGFILES_DIR = USER_HOME_PATH / EXPERIMENT_GROUP / \"logfiles\" / EXPERIMENT_ID\n",
    "LOGFILES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Logfiles werden gespeichert in: {LOGFILES_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw state_dict from /dss/dsshome1/08/di97ren/xView2_all_data/checkpoints/001_best_siamese_unet_state.pth\n",
      "Checkpoint erfolgreich in DataParallel-Modell geladen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference:  68%|██████▊   | 40/59 [00:59<00:22,  1.20s/batch, Samples=1280, Avg time/batch=1.0751s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Modell initialisieren\n",
    "model = SiameseUnet(num_pre_classes=2, num_post_classes=6)\n",
    "model.to(device)\n",
    "\n",
    "best_checkpoint_path = find_best_checkpoint(CHECKPOINTS_DIR, EXPERIMENT_ID)\n",
    "# Besten Checkpoint laden\n",
    "model = load_checkpoint(model, best_checkpoint_path)\n",
    "results = inference(model, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.viz import vizualize_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualize_predictions(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/08/di97ren/04-geo-oma24/xView2SiameseUNet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import subprocess\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "import yaml\n",
    "\n",
    "base_dir = Path(os.getcwd()).parent  # Gehe einen Ordner zurück vom aktuellen Arbeitsverzeichnis\n",
    "config_path = base_dir / \"notebooks\" / \"config1.yaml\"\n",
    "print(base_dir)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference-Ergebnisse werden gespeichert in: /dss/dsshome1/08/di97ren/xView2_all_data/inference_results/001\n"
     ]
    }
   ],
   "source": [
    "USER = config[\"data\"][\"user\"]\n",
    "USER_HOME_PATH = Path(f\"/dss/dsshome1/08/{USER}\")\n",
    "\n",
    "# Pathes to store experiment informations in:\n",
    "EXPERIMENT_GROUP = config[\"data\"][\"experiment_group\"]\n",
    "EXPERIMENT_ID = config[\"data\"][\"experiment_id\"]\n",
    "\n",
    "USER_HOME_PATH = Path(f\"/dss/dsshome1/08/{USER}\")\n",
    "RESULTS_DIR = USER_HOME_PATH / EXPERIMENT_GROUP / \"inference_results\" / EXPERIMENT_ID\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Inference-Ergebnisse werden gespeichert in: {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_results = list(RESULTS_DIR.glob(\"inference_results_*.pkl\"))\n",
    "if existing_results:\n",
    "    print(\"Gefundene bestehende Inference-Ergebnisse:\")\n",
    "    for i, result_file in enumerate(existing_results):\n",
    "        file_time = time.ctime(result_file.stat().st_mtime)\n",
    "        file_size = result_file.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"{i+1}. {result_file.name} - {file_time} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    use_existing = input(\"\\nBestehende Ergebnisse verwenden? (y/n): \").lower()\n",
    "    if use_existing == 'y':\n",
    "        idx = int(input(\"Nummer des zu verwendenden Ergebnisses eingeben: \")) - 1\n",
    "        results_file = existing_results[idx]\n",
    "        with open(results_file, 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "        print(f\"Ergebnisse aus {results_file} geladen.\")\n",
    "    else:\n",
    "        # Inference-Skript ausführen\n",
    "        run_inference = True\n",
    "else:\n",
    "    run_inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Inference-Prozess...\n",
      "Fehler beim Ausführen des Inference-Skripts:\n",
      "Traceback (most recent call last):\n",
      "  File \"/dss/dsshome1/08/di97ren/04-geo-oma24/xView2SiameseUNet/notebooks/inference_subprocess.py\", line 143, in <module>\n",
      "    model = load_checkpoint(model, best_checkpoint_path)\n",
      "  File \"/dss/dsshome1/08/di97ren/04-geo-oma24/xView2SiameseUNet/notebooks/utils/inference.py\", line 21, in load_checkpoint\n",
      "    state_dict = checkpoint['model_state_dict']\n",
      "                 ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'model_state_dict'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'run_inference' in locals() and run_inference:\n",
    "    print(\"Starte Inference-Prozess...\")\n",
    "    try:\n",
    "        result = subprocess.run([\n",
    "            \"python\", \"inference_subprocess.py\",\n",
    "            \"--user\", USER,\n",
    "            \"--experiment_group\", config[\"data\"][\"experiment_group\"],\n",
    "            \"--experiment_id\", config[\"data\"][\"experiment_id\"],\n",
    "            \"--batch_size\", \"8\",\n",
    "            \"--save_results\"\n",
    "        ], capture_output=True, text=True, check=False)  # check=False um die Exception zu vermeiden\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            print(\"Fehler beim Ausführen des Inference-Skripts:\")\n",
    "            print(result.stderr)\n",
    "        else:\n",
    "            print(\"Inference erfolgreich abgeschlossen!\")\n",
    "            print(result.stdout)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Ausführen des Subprozesses: {e}\")\n",
    "    # try:\n",
    "    #     # Du kannst hier Argumente anpassen\n",
    "    #     result = subprocess.run([\n",
    "    #         \"python\", \"utils/inference_subprocess.py\",\n",
    "    #         \"--user\", USER,\n",
    "    #         \"--experiment_group\", EXPERIMENT_GROUP,\n",
    "    #         \"--experiment_id\", EXPERIMENT_ID,\n",
    "    #         \"--batch_size\", \"8\",\n",
    "    #         \"--save_results\"\n",
    "    #     ], capture_output=True, text=True, check=True)\n",
    "        \n",
    "    #     print(\"Inference erfolgreich abgeschlossen!\")\n",
    "    #     print(result.stdout)\n",
    "        \n",
    "    #     # Suche nach der neuesten Ergebnis-Datei\n",
    "    #     latest_result = max(RESULTS_DIR.glob(\"inference_results_*.pkl\"), key=os.path.getmtime)\n",
    "    #     with open(latest_result, 'rb') as f:\n",
    "    #         results = pickle.load(f)\n",
    "    #     print(f\"Neueste Ergebnisse aus {latest_result} geladen.\")\n",
    "        \n",
    "    # except subprocess.CalledProcessError as e:\n",
    "    #     print(\"Fehler beim Ausführen des Inference-Skripts:\")\n",
    "    #     print(e.stderr)\n",
    "    #     raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance-Metriken anzeigen\n",
    "if 'results' in locals():\n",
    "    perf = results['performance']\n",
    "    print(f\"Anzahl der verarbeiteten Samples: {perf['total_samples']}\")\n",
    "    print(f\"Gesamte Verarbeitungszeit: {perf['total_processing_time']:.2f} Sekunden\")\n",
    "    print(f\"Durchschnittliche Zeit pro Sample: {perf['avg_time_per_sample']:.4f} Sekunden\")\n",
    "    \n",
    "    print(\"\\nPre-Disaster Klassenverteilung:\")\n",
    "    for cls, count in perf['pre_class_distribution'].items():\n",
    "        print(f\"  Klasse {cls}: {count} Pixel\")\n",
    "    \n",
    "    print(\"\\nPost-Disaster Klassenverteilung:\")\n",
    "    for cls, count in perf['post_class_distribution'].items():\n",
    "        print(f\"  Klasse {cls}: {count} Pixel\")\n",
    "\n",
    "# %%\n",
    "# Visualisierungsfunktion importieren und ausführen\n",
    "from visualize import visualize_predictions  # Passe an deine Importstruktur an\n",
    "\n",
    "# Visualisiere eine bestimmte Anzahl von Samples\n",
    "num_samples_to_visualize = 5\n",
    "save_dir = RESULTS_DIR / \"visualizations\"\n",
    "visualize_predictions(results, num_samples=num_samples_to_visualize, save_dir=save_dir)\n",
    "\n",
    "# Zeige einige der generierten Bilder im Notebook an\n",
    "visualizations = list(save_dir.glob(\"prediction_*.png\"))\n",
    "for vis_file in visualizations[:3]:  # Zeige die ersten 3 Bilder\n",
    "    display(HTML(f'<img src=\"{vis_file}\" width=\"800\">'))\n",
    "\n",
    "# Zeige auch die Klassenverteilung an\n",
    "display(HTML(f'<img src=\"{save_dir}/class_distribution.png\" width=\"800\">'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
