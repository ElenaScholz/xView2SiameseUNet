{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following preprocessing steps will be done:\n",
    "1. Convert GeoTiffs to PNG images\n",
    "2. Read in the Label Information\n",
    "3. For Pre-images: create target mask with 0 for background and 1 for building\n",
    "4. For Post-images: create target mask with 0 for background, 1 for no damage, 2 for minor damage, 3 for major damage, 4 for destroyed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from shapely.wkt import loads\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from shapely import Polygon\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from Utils.preprocessing import extract_features, load_label_data, process_label_metadata, process_features, make_label_dictionary, geotiff_converter, create_disaster_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPC Terrabyte\n",
    "# adapt the user to your needs\n",
    "USER = \"di97ren\"\n",
    "# keep the following unchanged\n",
    "ROOT = Path(\"/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022\")\n",
    "USER_PATH = ROOT / f\"users/{USER}\"\n",
    "DATA_PATH = ROOT / \"data\"\n",
    "\n",
    "DATASET_ROOT = DATA_PATH / folder_name\n",
    "\n",
    "DATA_FOLDER = DATASET_ROOT / \"tier1\" # this has to be changed in respect to the folder (tier1, tier3, hold, test)\n",
    "\n",
    "IMAGE_FOLDER = DATA_FOLDER / \"images/\"\n",
    "\n",
    "LABEL_FOLDER = DATA_FOLDER / \"labels/\"\n",
    "\n",
    "TARGET_FOLDER = DATA_FOLDER / \"targets/\"\n",
    "\n",
    "PNG_FOLDER = DATA_FOLDER / \"png_images/\"\n",
    "# Path Configuration to the xview2 Subset\n",
    "\n",
    "def path_configuration(user_name: str,\n",
    "    folder_name: str # possible values: [tier1, tier3, hold, test]\n",
    "    ):\n",
    "\n",
    "                       # keep the following unchanged\n",
    "    ROOT = Path(\"/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022\")\n",
    "    USER_PATH = ROOT / f\"users/{USER}\"\n",
    "    DATA_PATH = ROOT / \"data\"\n",
    "\n",
    "    DATASET_ROOT = DATA_PATH / folder_name\n",
    "\n",
    "    DATA_FOLDER = DATASET_ROOT / \"tier1\" # this has to be changed in respect to the folder (tier1, tier3, hold, test)\n",
    "\n",
    "    IMAGE_FOLDER = DATA_FOLDER / \"images/\"\n",
    "\n",
    "    LABEL_FOLDER = DATA_FOLDER / \"labels/\"\n",
    "\n",
    "    TARGET_FOLDER = DATA_FOLDER / \"targets/\"\n",
    "\n",
    "    PNG_FOLDER = DATA_FOLDER / \"png_images/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022/data/xview2/tier1/images\n"
     ]
    }
   ],
   "source": [
    "print(IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xef in position 20: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m label_paths:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(label, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         label_data.append(\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/04-geo-oma24/assignment_04_geo_oma24-xView2/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:791\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    789\u001b[39m     convert_axes = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m json_reader = \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/04-geo-oma24/assignment_04_geo_oma24-xView2/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:905\u001b[39m, in \u001b[36mJsonReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[39m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mujson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    904\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._get_data_from_filepath(filepath_or_buffer)\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/04-geo-oma24/assignment_04_geo_oma24-xView2/.venv/lib/python3.13/site-packages/pandas/io/json/_json.py:917\u001b[39m, in \u001b[36mJsonReader._preprocess_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.chunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nrows):\n\u001b[32m    916\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m         data = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.chunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nrows):\n\u001b[32m    919\u001b[39m     data = StringIO(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xef in position 20: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = os.listdir(LABEL_FOLDER)\n",
    "\n",
    "\n",
    "label_paths = []\n",
    "\n",
    "\n",
    "for l in labels:\n",
    "    label_paths.append(os.path.join(LABEL_FOLDER / l))\n",
    "\n",
    "\n",
    "label_data = []\n",
    "\n",
    "for label in label_paths:\n",
    "    with open(label, \"r\") as file:\n",
    "        label_data.append(pd.read_json(file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(features):\n",
    "    \"\"\"Extract polygons, feature types, and damage classes from features.\"\"\"\n",
    "    return {\n",
    "        'geometries': [feature['wkt'] for feature in features],\n",
    "        'class_name': [feature['properties'].get('feature_type', 'unknown') for feature in features],\n",
    "        'damage_class': [feature['properties'].get('subtype', 'no-damage') for feature in features]\n",
    "    }\n",
    "\n",
    "def load_label_data(label_paths):\n",
    "    \"\"\"Load label data from the specified paths.\"\"\"\n",
    "    label_data = []\n",
    "    for label in label_paths:\n",
    "        with open(label, \"r\") as file:\n",
    "            label_data.append(pd.read_json(file))\n",
    "    return label_data\n",
    "\n",
    "def process_label_metadata(label):\n",
    "     \"\"\"Process metadata from the label.\"\"\"\n",
    "     metadata = label['metadata']\n",
    "     return {\n",
    "        'img_name': metadata['img_name'][:-4],  # Remove file extension\n",
    "        'disaster': metadata['disaster'],\n",
    "        'disaster_type': metadata['disaster_type']\n",
    "    }\n",
    "\n",
    "def process_features(label, damage_codes):\n",
    "     \"\"\"Process features from the label and apply damage codes.\"\"\"\n",
    "     \n",
    "     feature_data = label['features']['xy']\n",
    "     feature_dict = extract_features(feature_data)\n",
    "    \n",
    "     df = pd.DataFrame(feature_dict)\n",
    "    \n",
    "    # Add metadata columns to the dataframe\n",
    "     metadata = process_label_metadata(label)\n",
    "     for key, value in metadata.items():\n",
    "        df[key] = value\n",
    "\n",
    "    # Apply damage codes\n",
    "     df['damage_code'] = df['damage_class'].apply(lambda x: damage_codes.get(x, 999))\n",
    "\n",
    "    # Convert damage codes to integers\n",
    "     df['damage_code'] = df['damage_code'].astype(int)\n",
    "\n",
    "     return df\n",
    "\n",
    "def make_label_dictionary(input_directory, damage_codes):\n",
    "    \"\"\"Create a dictionary of labels with associated metadata and damage codes.\"\"\"\n",
    "    label_paths = [os.path.join(input_directory, f) for f in os.listdir(input_directory)]\n",
    "    label_data = load_label_data(label_paths)\n",
    "    \n",
    "    label_dictionary = {}\n",
    "    \n",
    "    for label in label_data:\n",
    "        img_name = label['metadata']['img_name'][:-4]  # Remove file extension\n",
    "        label_df = process_features(label, damage_codes)\n",
    "        \n",
    "        # Add the processed dataframe to the dictionary\n",
    "        label_dictionary[img_name] = label_df\n",
    "\n",
    "    return label_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The damage map below will be used to link numerical values to the post-disaster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_codes = {\n",
    "    'no-damage' : 1,\n",
    "    'minor-damage' : 2,\n",
    "    'major-damage' : 3,\n",
    "    'destroyed' : 4,\n",
    "    'un-classified' : 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dictionary = make_label_dictionary(LABEL_FOLDER, damage_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometries</th>\n",
       "      <th>class_name</th>\n",
       "      <th>damage_class</th>\n",
       "      <th>img_name</th>\n",
       "      <th>disaster</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>damage_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((77.59030516034854 0, 85.668946993448...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((193.5972809756205 0, 199.71625600776...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((248.9587337209918 0, 253.10010278041...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((265.7093697033929 0, 278.09344922398...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((320.1406641054013 64.68679692648156,...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>POLYGON ((163.5865766441175 312.7090464655843,...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>POLYGON ((927.0221567239959 2.697160824916165,...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>POLYGON ((29.93195910739135 309.3868047489998,...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>POLYGON ((192.6590626088126 346.1349797782409,...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>POLYGON ((125.0393885018527 924.2362183492361,...</td>\n",
       "      <td>building</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>hurricane-matthew_00000044_pre_disaster</td>\n",
       "      <td>hurricane-matthew</td>\n",
       "      <td>wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometries class_name  \\\n",
       "0    POLYGON ((77.59030516034854 0, 85.668946993448...   building   \n",
       "1    POLYGON ((193.5972809756205 0, 199.71625600776...   building   \n",
       "2    POLYGON ((248.9587337209918 0, 253.10010278041...   building   \n",
       "3    POLYGON ((265.7093697033929 0, 278.09344922398...   building   \n",
       "4    POLYGON ((320.1406641054013 64.68679692648156,...   building   \n",
       "..                                                 ...        ...   \n",
       "268  POLYGON ((163.5865766441175 312.7090464655843,...   building   \n",
       "269  POLYGON ((927.0221567239959 2.697160824916165,...   building   \n",
       "270  POLYGON ((29.93195910739135 309.3868047489998,...   building   \n",
       "271  POLYGON ((192.6590626088126 346.1349797782409,...   building   \n",
       "272  POLYGON ((125.0393885018527 924.2362183492361,...   building   \n",
       "\n",
       "    damage_class                                 img_name           disaster  \\\n",
       "0      no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "1      no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "2      no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "3      no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "4      no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "..           ...                                      ...                ...   \n",
       "268    no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "269    no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "270    no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "271    no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "272    no-damage  hurricane-matthew_00000044_pre_disaster  hurricane-matthew   \n",
       "\n",
       "    disaster_type  damage_code  \n",
       "0            wind            1  \n",
       "1            wind            1  \n",
       "2            wind            1  \n",
       "3            wind            1  \n",
       "4            wind            1  \n",
       "..            ...          ...  \n",
       "268          wind            1  \n",
       "269          wind            1  \n",
       "270          wind            1  \n",
       "271          wind            1  \n",
       "272          wind            1  \n",
       "\n",
       "[273 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dictionary['hurricane-matthew_00000044_pre_disaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geotiff_converter(image_directoy: dir , output_directory: dir):\n",
    "\n",
    "    '''\n",
    "    This function takes the input geotiff images and converts them to png images \n",
    "    '''\n",
    "\n",
    "    images = os.listdir(image_directoy) # get all image names \n",
    "\n",
    "        \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(output_directory)\n",
    "        print(f\"Directory '{output_directory}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{output_directory}' already exists.\")\n",
    "\n",
    "\n",
    "    for i in images: # iterate over each image and open it with rasterio\n",
    "\n",
    "        png_name = i[:-4] + \".png\"\n",
    "\n",
    "        with rio.open( image_directoy / i) as src:\n",
    "            r , g , b = src.read(1), src.read(2), src.read(3)\n",
    "\n",
    "            img = np.stack([r, g, b], axis = -1) # Stack the bands to create and np image array \n",
    "\n",
    "            # normalize image values:\n",
    "            if img.dtype != np.uint8:\n",
    "                img = ((img - img.min()) / (img.max() - img.min()) * 255).astype(np.uint8)\n",
    "\n",
    "            png_image = Image.fromarray(img) # make it an image\n",
    "\n",
    "            png_image.save( output_directory / png_name) # save the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022/data/xview2-subset/png_images' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Apply geotiff_converter to all input images:\n",
    "geotiff_converter(IMAGE_FOLDER, PNG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_disaster_targets (png_image_directory: dir,\n",
    "                             label_dictionary: dict, \n",
    "                             target_output_directory: dir):\n",
    "    \n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(target_output_directory):\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(target_output_directory)\n",
    "        print(f\"Directory '{target_output_directory}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{target_output_directory}' already exists.\")\n",
    "\n",
    "    \n",
    "    pngs = os.listdir(png_image_directory)\n",
    "\n",
    "\n",
    "    for image_name in pngs:\n",
    "\n",
    "        if \"pre_disaster\" in image_name:\n",
    "            label = label_dictionary[image_name[:-4]]['geometries'] # retrieving geometries from the label\n",
    "            gdf = gpd.GeoDataFrame(geometry=label.apply(wkt.loads)) # creating a geodataframe\n",
    "\n",
    "\n",
    "            image = Image.open(png_image_directory / image_name) # open the corresponding image\n",
    "\n",
    "            width,height = image.size # getting width and height information\n",
    "\n",
    "            # Erstelle eine leere Maske (0 = Hintergrund, 1 = Gebäude/Label)\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "            # Rasterisiere die Polygone in die Maske\n",
    "            shapes = [(geom, 1) for geom in gdf.geometry]  # Alle Polygone mit Wert 1 versehen\n",
    "            mask = rio.features.rasterize(shapes, out_shape=(height, width))\n",
    "            mask_img = Image.fromarray(mask.astype(np.uint8))\n",
    "            #mask_img = Image.fromarray(mask * 255)  # Skaliere 0/1 auf 0/255 für Darstellung\n",
    "            mask_img.save(target_output_directory / image_name )\n",
    "\n",
    "        else:\n",
    "            label = label_dictionary[image_name[:-4]]\n",
    "            gdf_post = gpd.GeoDataFrame({\n",
    "                'geometry': [wkt.loads(wkt_string) for wkt_string in label['geometries']],\n",
    "                'damage_code': label['damage_code']\n",
    "            })\n",
    "\n",
    "            image = Image.open(png_image_directory / image_name) # open the corresponding image\n",
    "\n",
    "            width,height = image.size # getting width and height information\n",
    "\n",
    "            # Erstelle eine leere Maske (0 = Hintergrund, 1 = Gebäude/Label)\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "            # Rasterisiere die Polygone in die Maske\n",
    "            shapes = [(geom, damage) for geom, damage in zip(gdf_post.geometry, gdf_post.damage_code)]\n",
    "            mask = rio.features.rasterize(shapes, out_shape=(height, width))\n",
    "\n",
    "            mask_img = Image.fromarray(mask.astype(np.uint8))\n",
    "\n",
    "            mask_img.save(target_output_directory / image_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/dss/dsstbyfs02/pn49ci/pn49ci-dss-0022/data/xview2-subset/targets' already exists.\n"
     ]
    }
   ],
   "source": [
    "create_disaster_targets(PNG_FOLDER, label_dictionary, TARGET_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
